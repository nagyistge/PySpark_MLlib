{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mockup Dataset Generator on PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SQLContext\n",
    "from pyspark.mllib.random import RandomRDDs\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the speed of RDD random generator\n",
    "gender_1 = RandomRDDs.normalRDD(sc, 10000, seed = 1).map(lambda x: np.round(x))\n",
    "gender_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the speed of numpy random generator\n",
    "gender_2 = np.random.randint(0,2,size = 10000)\n",
    "len(gender_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the size 10000, numpy is faster than spark RDD. Use numpy to build arrays then convert to pyspark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create numpy arrays \n",
    "biologic = np.random.randint(0,2,size = 10000)\n",
    "gender = np.random.randint(0,2,size = 10000)\n",
    "age = np.random.randint(18,85,size = 10000)\n",
    "num_ocs_1 = np.random.randint(0,12,size = 10000)\n",
    "days_last_ocs = np.random.randint(0,365,size = 10000)\n",
    "num_ics_1 = np.random.randint(0,12,size = 10000)\n",
    "days_last_ics = np.random.randint(0,365,size = 10000)\n",
    "num_laba_1 = np.random.randint(0,12,size = 10000)\n",
    "days_last_laba = np.random.randint(0,365,size = 10000)\n",
    "pres_1 = np.random.randint(0,2,size = 10000)\n",
    "pres_2 = np.random.randint(0,2,size = 10000)\n",
    "presgroup_1 = np.random.randint(0,4,size = 10000)\n",
    "presgroup_2 = np.random.randint(0,4,size = 10000)\n",
    "payer_1 = np.random.randint(0,2,size = 10000)\n",
    "payer_2 = np.random.randint(0,2,size = 10000)\n",
    "alle_1 = np.random.randint(0,2,size = 10000)\n",
    "alle_2 = np.random.randint(0,2,size = 10000)\n",
    "eos_max_1 = np.random.randint(0,36,size = 10000)\n",
    "days_eos = np.random.randint(0,365,size = 10000)\n",
    "cop_d = np.random.randint(0,2,size = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = ['biologic', 'gender', 'age', 'num_ocs_1', 'time_ocs',  'num_ICS_1', 'time_ics', 'num_laba_1', 'time_laba', 'Pres_1', 'Pres_2', 'Presgroup_1', 'Presgroup_2',  'Payer_1',  'Payer_2', 'Alle_1', 'Alle_2', 'EoS_1', 'Time_eos_1', 'COP_D']\n",
    "\n",
    "p_df = pd.DataFrame({col_names[0]:biologic,col_names[1]:gender,col_names[2]:age,col_names[3]:num_ocs_1,col_names[4]:days_last_ocs,col_names[5]: num_ics_1,col_names[6]:days_last_ics,col_names[7]:num_laba_1,col_names[8]:days_last_laba,col_names[9]: pres_1,col_names[10]:pres_2,col_names[11]:presgroup_1,col_names[12]:presgroup_2,col_names[13]:payer_1,col_names[14]:payer_2,col_names[15]:alle_1,col_names[16]:alle_2,col_names[17]:eos_max_1,col_names[18]:days_eos,col_names[19]:cop_d})\n",
    "p_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx.createDataFrame(p_df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dataframe to s3 as csv files (with partition)\n",
    "filepath = '/mnt/somefilepath'\n",
    "df.write.format('com.databricks.spark.csv').option('header','True').save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "Mockup Dataset Generator_ims",
  "notebookId": 589076
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
